{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\project\\dog-breed-classification.tf-master\\datasets에 있는 convert_tf_record.py를 datasets에 카피\n",
    "\n",
    "(base) C:\\project\\dog-breed-classification.tf-master>python create_tf_record.py --dataset_name=mnist  --dataset_dir=/tmp/raw_data/mnist \n",
    "\n",
    "(base) C:\\project\\dog-breed-classification.tf-master>python create_tf_record.py --dataset_name=mnist  --dataset_dir=/tmp/raw_data/dog\n",
    "\n",
    "(base) C:\\project\\dog-breed-classification.tf-master>python create_tf_record.py --dataset_name=mnist  --dataset_dir=/tmp/raw_data/flowers \n",
    "\n",
    "(base) C:\\project\\dog-breed-classification.tf-master>python create_tf_record.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/tmp/flowers\\\\images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1367176d82ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1367176d82ca>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must supply the dataset directory with --dataset_dir'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mconvert_tf_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\slim_tf_1_9\\datasets\\convert_tf_record.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(dataset_name, dataset_dir, num_shards, ratio_val)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mphoto_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_filenames_and_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[0mclass_names_to_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\slim_tf_1_9\\datasets\\convert_tf_record.py\u001b[0m in \u001b[0;36m_get_filenames_and_classes\u001b[1;34m(dataset_dir)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mdirectories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '/tmp/flowers\\\\images'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "__author__ = 'socurites@gmail.com'\n",
    "\n",
    "\"\"\"\n",
    "이미지 데이터를 학습/평가를 위한 TFRecord 포맷으로 변환\n",
    "\n",
    "# Ref: TensorFlow-Slim image classification library\n",
    "       https://github.com/tensorflow/models/tree/master/slim\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\"\"\"\n",
    "# 훈련 데이터셋의 구조\n",
    "raw_data/\n",
    "  |- flowers/\n",
    "       |- images/\n",
    "           |- class-1/\n",
    "           |- class-2/\n",
    "           |- class-3/\n",
    "           |- class-4/\n",
    "           |-- ...\n",
    "\n",
    "# MNITS의 경우\n",
    "raw_data/\n",
    "  |- mnist/\n",
    "       |- images/\n",
    "           |- 0/\n",
    "           |- 1/\n",
    "           |- 2/\n",
    "           |- 3/\n",
    "           |-- ...\n",
    "\"\"\"\n",
    "\n",
    "# 아래 코드는 flowers/ 데이터를 다운로드 후 TFRecord로 변환하는 코드임\n",
    "# 아래 코드를 약간 변형해서 사용\n",
    "# https://github.com/tensorflow/models/blob/master/slim/download_and_convert_data.py\n",
    "\n",
    "from datasets import convert_tf_record\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_name',\n",
    "    #'mnist',\n",
    "    #'dog',\n",
    "    'flowers',\n",
    "    'The name of the dataset prefix.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_dir',\n",
    "    #'./raw_data/mnist',\n",
    "    #'./raw_data/dog',\n",
    "    #'/tmp/raw_data/mnist',\n",
    "    #'/tmp/raw_data/dog',\n",
    "    '/tmp/flowers',\n",
    "    'A directory containing a set of subdirectories representing class names. Each subdirectory should contain PNG or JPG encoded images.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_shards',\n",
    "    5,\n",
    "    'A number of sharding for TFRecord files(integer).')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'ratio_val',\n",
    "    0.2,\n",
    "    'A ratio of validation datasets for TFRecord files(flaot, 0 ~ 1).')\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    if not FLAGS.dataset_name:\n",
    "        raise ValueError('You must supply the dataset name with --dataset_name')\n",
    "    if not FLAGS.dataset_dir:\n",
    "        raise ValueError('You must supply the dataset directory with --dataset_dir')\n",
    "\n",
    "    convert_tf_record.run(FLAGS.dataset_name, FLAGS.dataset_dir, FLAGS.num_shards, FLAGS.ratio_val)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
